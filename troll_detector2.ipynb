{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ml packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3dee568776c08512c89</td>\n",
       "      <td>What is the role of Lua in Civ4?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bdb84f519e7b46e7b7bb</td>\n",
       "      <td>What are important chapters in Kannada for 10 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29c88db470e2eb5c97ad</td>\n",
       "      <td>Do musicians get royalties from YouTube?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3387d99bf2c3227ae8f1</td>\n",
       "      <td>What is the difference between Scaling Social ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e79fa5038f765d0f2e7e</td>\n",
       "      <td>Why do elevators go super slow right before th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  a3dee568776c08512c89                   What is the role of Lua in Civ4?   \n",
       "1  bdb84f519e7b46e7b7bb  What are important chapters in Kannada for 10 ...   \n",
       "2  29c88db470e2eb5c97ad           Do musicians get royalties from YouTube?   \n",
       "3  3387d99bf2c3227ae8f1  What is the difference between Scaling Social ...   \n",
       "4  e79fa5038f765d0f2e7e  Why do elevators go super slow right before th...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset\n",
    "train_df = pd.read_csv('../AskReddit Dataset/train.csv')\n",
    "test_df = pd.read_csv('../AskReddit Dataset/test.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16                                                     What stupid things do Indians do when in your country?\n",
       "31                             Can I sue my parents for giving birth to me when I did not want them to do so?\n",
       "32                          What are your views about sexual relationship between a widow mother and her son?\n",
       "33        You became an atheist, and after 2 years you fall and break your back. You are left paralyzed fr...\n",
       "90                                    Why aren't we protesting for government control instead of gun control?\n",
       "                                                         ...                                                 \n",
       "652967              What is a liberal's understanding of the difference between pollution and climate change?\n",
       "653021    Do unattractive or average-looking men ever get a girlfriend who actually loves them or do they ...\n",
       "653029                                                                   How can I grab my aunties boobs! :p?\n",
       "653034                                                            Any girls like to be treated like sex toys?\n",
       "653049    I'm liberal, but also concerned that a lot of Quora questions are phrased to make conservatives ...\n",
       "Name: question_text, Length: 40405, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose elements from df where target = 1\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "df_1 = train_df[train_df['target'] == 1]\n",
    "df_1[\"question_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    612656\n",
       "1     40405\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see value count order of target\n",
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.93813\n",
       "1    0.06187\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of troll questions in the dataset\n",
    "train_df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graphing label counts\n",
    "sns.countplot(x='target', data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target'>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# violin plot of label value counts\n",
    "sns.violinplot(x='target', data=train_df, hue='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a preprocessing class\n",
    "class Preprocessor:\n",
    "    \n",
    "    def __init__(self,df) -> None:\n",
    "        self.df = df\n",
    "\n",
    "    # convert all charecters to lower case\n",
    "    def convertToLower(self):\n",
    "        self.df['question_text'] = self.df['question_text'].apply(lambda x: x.lower())\n",
    "        return self.df\n",
    "\n",
    "    # remove stop words\n",
    "    def removeStopWords(self):\n",
    "        stop = stopwords.words('english')\n",
    "        self.df['question_text'] = self.df['question_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    # remove punctuation\n",
    "    def removePunctuation(self):\n",
    "        self.df['question_text'] = self.df['question_text'].str.replace('[^\\w\\s]','')\n",
    "        return self.df\n",
    "\n",
    "    # remove numbers\n",
    "    def removeNumbers(self):\n",
    "        self.df['question_text'] = self.df['question_text'].str.replace('[0-9]','')\n",
    "        return self.df\n",
    "\n",
    "    # remove whitespaces\n",
    "    def removeWhitespaces(self):\n",
    "        self.df['question_text'] = self.df['question_text'].apply(lambda x: ' '.join(x.split()))\n",
    "        return self.df\n",
    "\n",
    "    # remove urls\n",
    "    def removeURLs(self):\n",
    "        self.df['question_text'] = self.df['question_text'].str.replace('https?://\\S+|www\\.\\S+','')\n",
    "        return self.df\n",
    "        \n",
    "\n",
    "    # stemmer algorithm\n",
    "    def stemmer(self):\n",
    "        stemmer = SnowballStemmer()\n",
    "        def stem_words(text):\n",
    "            return \" \".join([stemmer.stem(word) for word in text.split()])  \n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].apply(lambda x: stem_words(x))\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    # lemmatizing\n",
    "    def lemmatize(self):\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        def lemmatize_words(text):\n",
    "            return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])  \n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].apply(lambda x: lemmatize_words(x))\n",
    "        return self.df\n",
    "\n",
    "    # remove id and index columns\n",
    "    def removeUnwantedCols(self,col):\n",
    "        print(self.df.shape)\n",
    "        self.df = self.df.drop(col,axis=1)\n",
    "        return self.df\n",
    "    \n",
    "    def preprocess(self):\n",
    "        # self.df = self.convertToLower()\n",
    "        # self.df = self.removeStopWords()\n",
    "        # self.df = self.removePunctuation()\n",
    "        # self.df = self.removeNumbers()\n",
    "        # self.df = self.removeURLs()\n",
    "        # self.df = self.removeWhitespaces()\n",
    "        # self.df = self.stemmer()\n",
    "        # self.df = self.lemmatize()\n",
    "        self.df = self.removeUnwantedCols(['qid'])\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653061, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>role lua civ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>important chapters kannada  icse</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>musicians get royalties youtube</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>difference scaling social enterprises social franchising</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elevators go super slow right doors open</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question_text  target\n",
       "0                                              role lua civ       0\n",
       "1                         important chapters kannada  icse        0\n",
       "2                           musicians get royalties youtube       0\n",
       "3  difference scaling social enterprises social franchising       0\n",
       "4                  elevators go super slow right doors open       0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproccesor = Preprocessor(train_df)\n",
    "preprocessed_df = preproccesor.preprocess()\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653061, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get shape of preprocessed_df\n",
    "preprocessed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a get train and test data class\n",
    "class TrainTestData:\n",
    "\n",
    "    def __init__(self,trainDf,testDf) -> None:\n",
    "        self.trainDf = trainDf\n",
    "        self.testDf = testDf\n",
    "\n",
    "    \n",
    "    def get_X(self,minDocumentCount):\n",
    "        \n",
    "        # concatinate trainDf and testDf\n",
    "        self.appendDf = pd.concat([self.trainDf['question_text'],self.testDf['question_text']],axis=0)\n",
    "        \n",
    "        vectorizer = CountVectorizer()\n",
    "        vectorizer.fit(self.appendDf)\n",
    "\n",
    "        self.trainData = vectorizer.transform(self.trainDf['question_text'])\n",
    "        print(self.trainData.shape)\n",
    "\n",
    "        self.testData = vectorizer.transform(self.testDf['question_text'])\n",
    "        print(self.testData.shape)\n",
    "        self.X = self.trainData\n",
    "\n",
    "\n",
    "    def get_Y(self):\n",
    "        self.Y = self.trainDf['target']\n",
    "        return self.Y\n",
    "\n",
    "    def testTrainSplit(self):\n",
    "        self.X_train, self.X_test, self.Y_train, self.Y_test = model_selection.train_test_split(self.X, self.Y, test_size=0.2, random_state=0)\n",
    "        return self.X_train, self.X_test, self.Y_train, self.Y_test\n",
    "\n",
    "    def get_X_test(self):\n",
    "        return self.testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653061, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1208: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653061, 3660031)\n",
      "(653061, 3660031)\n"
     ]
    }
   ],
   "source": [
    "testPreprocessor = Preprocessor(test_df)\n",
    "preprocessed_test_df = testPreprocessor.preprocess()\n",
    "preprocessed_test_df.head()\n",
    "\n",
    "getTTData = TrainTestData(preprocessed_df,preprocessed_test_df)\n",
    "X = getTTData.get_X(1)\n",
    "y = getTTData.get_Y()\n",
    "X_train,X_test,Y_train,Y_test = getTTData.testTrainSplit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrModel = LogisticRegression(solver='liblinear',penalty=\"l1\")\n",
    "lrModel.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130613,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7853830815444047"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = Y_test\n",
    "cv_preds = lrModel.predict(X_test)\n",
    "print(cv_preds.shape)\n",
    "from sklearn.metrics import fbeta_score\n",
    "fbeta_score(y_actual, cv_preds, average='macro', beta=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear svm classification\n",
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7799023453739543"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = Y_test\n",
    "cv_preds = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "fbeta_score(y_actual, cv_preds, average='macro', beta=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14352/1233394284.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlrCvModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlrCvModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   2152\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"processes\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2154\u001b[1;33m         fold_coefs_ = Parallel(\n\u001b[0m\u001b[0;32m   2155\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[1;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m     coefs, Cs, n_iter = _logistic_regression_path(\n\u001b[0m\u001b[0;32m   1061\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    825\u001b[0m             )\n\u001b[0;32m    826\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"liblinear\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n\u001b[0m\u001b[0;32m    828\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1179\u001b[1;33m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[0;32m   1180\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lrCvModel = LogisticRegressionCV(cv=5, penalty='l1', solver='liblinear')\n",
    "lrCvModel.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdModel = SGDClassifier(loss='log', penalty='l1', alpha=0.0001, max_iter=1000, tol=None)\n",
    "sgdModel.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification using Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([130522,     91], dtype=int64))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mulNbClf = MultinomialNB().fit(X_train,Y_train)\n",
    "mulNbPreds = mulNbClf.predict(X_test)\n",
    "fbeta_score(Y_test, mulNbPreds, average='macro', beta=0.5)\n",
    "np.unique(mulNbPreds, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:37:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "xgbModel = XGBClassifier()\n",
    "xgbModel.fit(X_train, Y_train)\n",
    "xgbModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a csv out of the test data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653061, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653061,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lrModel.predict(getTTData.get_X_test())\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([627566,  25495], dtype=int64))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of unique counts of predictions\n",
    "np.unique(predictions, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a submission data frame from preprocessed_test_df and predictions\n",
    "submission_df = pd.DataFrame({'qid': test_df['qid'], 'target': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0a824224322f0a36025f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28af14c4e4777ce1273e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6892a52c51103dd95044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>badd9e8886d73fc1fe4e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ef178f82a465e4804ae</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  target\n",
       "0  0a824224322f0a36025f       0\n",
       "1  28af14c4e4777ce1273e       0\n",
       "2  6892a52c51103dd95044       0\n",
       "3  badd9e8886d73fc1fe4e       0\n",
       "4  4ef178f82a465e4804ae       0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    627566\n",
       "1     25495\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert submission_df to admiral_general_aladdin_submission1.csv\n",
    "submission_df.to_csv('admiral_general_aladdin_submission14_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
