{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ml packages\n",
    "\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, HashingVectorizer, TfidfVectorizer)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3dee568776c08512c89</td>\n",
       "      <td>What is the role of Lua in Civ4?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bdb84f519e7b46e7b7bb</td>\n",
       "      <td>What are important chapters in Kannada for 10 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29c88db470e2eb5c97ad</td>\n",
       "      <td>Do musicians get royalties from YouTube?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3387d99bf2c3227ae8f1</td>\n",
       "      <td>What is the difference between Scaling Social ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e79fa5038f765d0f2e7e</td>\n",
       "      <td>Why do elevators go super slow right before th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  a3dee568776c08512c89                   What is the role of Lua in Civ4?   \n",
       "1  bdb84f519e7b46e7b7bb  What are important chapters in Kannada for 10 ...   \n",
       "2  29c88db470e2eb5c97ad           Do musicians get royalties from YouTube?   \n",
       "3  3387d99bf2c3227ae8f1  What is the difference between Scaling Social ...   \n",
       "4  e79fa5038f765d0f2e7e  Why do elevators go super slow right before th...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "train_df = pd.read_csv(\"../AskReddit Dataset/AskReddit Dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"../AskReddit Dataset/AskReddit Dataset/test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    612656\n",
       "1     40405\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see value count order of target\n",
    "train_df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a preprocessing class\n",
    "class Preprocessor:\n",
    "    def __init__(self, df) -> None:\n",
    "        self.df = df\n",
    "\n",
    "    # convert all charecters to lower case\n",
    "    def convertToLower(self):\n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].apply(lambda x: x.lower())\n",
    "        return self.df\n",
    "\n",
    "    # remove stop words\n",
    "    def removeStopWords(self):\n",
    "        stop = stopwords.words(\"english\")\n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].apply(\n",
    "            lambda x: \" \".join([word for word in x.split() if word not in stop])\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # remove punctuation\n",
    "    def removePunctuation(self):\n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].str.replace(\"[^\\w\\s]\", \"\")\n",
    "        return self.df\n",
    "\n",
    "    # remove numbers\n",
    "    def removeNumbers(self):\n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].str.replace(\"[0-9]\", \"\")\n",
    "        return self.df\n",
    "\n",
    "    # remove whitespaces\n",
    "    def removeWhitespaces(self):\n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].apply(\n",
    "            lambda x: \" \".join(x.split())\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # remove urls\n",
    "    def removeURLs(self):\n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].str.replace(\n",
    "            \"https?://\\S+|www\\.\\S+\", \"\"\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # snowball stemmer algorithm\n",
    "    def snowballstemmer(self):\n",
    "        stemmer = SnowballStemmer()\n",
    "\n",
    "        def stem_words(text):\n",
    "            return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].apply(\n",
    "            lambda x: stem_words(x)\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # port stemmer algorithm\n",
    "    def porterstemmer(self):\n",
    "        stemmer = PorterStemmer()\n",
    "\n",
    "        def stem_words(text):\n",
    "            return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].apply(\n",
    "            lambda x: stem_words(x)\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # lemmatizing\n",
    "    def lemmatize(self):\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        def lemmatize_words(text):\n",
    "            return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].apply(\n",
    "            lambda x: lemmatize_words(x)\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # remove id and index columns\n",
    "    def removeUnwantedCols(self, col):\n",
    "        print(self.df.shape)\n",
    "        self.df = self.df.drop(col, axis=1)\n",
    "        return self.df\n",
    "\n",
    "    # word tokenization using nltk\n",
    "    def wordTokenization(self):\n",
    "        self.df[\"question_text\"] = self.df[\"question_text\"].apply(\n",
    "            lambda x: nltk.word_tokenize(x)\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.df = self.convertToLower()\n",
    "        # self.df = self.removeStopWords()\n",
    "        self.df = self.removePunctuation()\n",
    "        # self.df = self.removeNumbers()\n",
    "        # self.df = self.removeURLs()\n",
    "        # self.df = self.removeWhitespaces()\n",
    "        # self.df = self.snowballstemmer()\n",
    "        # self.df = self.porterstemmer()\n",
    "        # self.df = self.lemmatize()\n",
    "        self.df = self.wordTokenization()\n",
    "        self.df = self.removeUnwantedCols([\"qid\"])\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRASANNA\\AppData\\Local\\Temp/ipykernel_5964/3858711618.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df[\"question_text\"] = self.df[\"question_text\"].str.replace(\"[^\\w\\s]\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653061, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[what, is, the, role, of, lua, in, civ4]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[what, are, important, chapters, in, kannada, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[do, musicians, get, royalties, from, youtube]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[what, is, the, difference, between, scaling, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[why, do, elevators, go, super, slow, right, b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text  target\n",
       "0           [what, is, the, role, of, lua, in, civ4]       0\n",
       "1  [what, are, important, chapters, in, kannada, ...       0\n",
       "2     [do, musicians, get, royalties, from, youtube]       0\n",
       "3  [what, is, the, difference, between, scaling, ...       0\n",
       "4  [why, do, elevators, go, super, slow, right, b...       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproccesor = Preprocessor(train_df)\n",
    "preprocessed_df = preproccesor.preprocess()\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRASANNA\\AppData\\Local\\Temp/ipykernel_5964/3858711618.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df[\"question_text\"] = self.df[\"question_text\"].str.replace(\"[^\\w\\s]\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653061, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[why, is, my, fish, tank, so, cloudy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[are, aap, supportersleaders, hypocrites]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[can, you, still, get, a, ticket, if, you, shu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[why, should, any, liberal, or, caring, person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[how, can, i, know, who, got, into, my, pc, us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text\n",
       "0              [why, is, my, fish, tank, so, cloudy]\n",
       "1          [are, aap, supportersleaders, hypocrites]\n",
       "2  [can, you, still, get, a, ticket, if, you, shu...\n",
       "3  [why, should, any, liberal, or, caring, person...\n",
       "4  [how, can, i, know, who, got, into, my, pc, us..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPreprocessor = Preprocessor(test_df)\n",
    "preprocessed_test_df = testPreprocessor.preprocess()\n",
    "preprocessed_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "feature_size = 256\n",
    "context_size = 5\n",
    "min_word = 1\n",
    "\n",
    "word_vec= word2vec.Word2Vec(preprocessed_df['question_text'], vector_size=feature_size, window=context_size, min_count=min_word, epochs=50, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.157692</td>\n",
       "      <td>-1.962667</td>\n",
       "      <td>-0.021549</td>\n",
       "      <td>-1.304941</td>\n",
       "      <td>1.056042</td>\n",
       "      <td>-1.409629</td>\n",
       "      <td>1.633958</td>\n",
       "      <td>-0.239701</td>\n",
       "      <td>0.867131</td>\n",
       "      <td>1.081947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443057</td>\n",
       "      <td>1.110562</td>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.645440</td>\n",
       "      <td>1.455143</td>\n",
       "      <td>-2.426267</td>\n",
       "      <td>-0.507591</td>\n",
       "      <td>0.627361</td>\n",
       "      <td>-0.553571</td>\n",
       "      <td>1.617401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>-0.950905</td>\n",
       "      <td>-2.366135</td>\n",
       "      <td>-2.126145</td>\n",
       "      <td>0.122318</td>\n",
       "      <td>0.181524</td>\n",
       "      <td>-0.635590</td>\n",
       "      <td>2.056228</td>\n",
       "      <td>-0.545641</td>\n",
       "      <td>0.922501</td>\n",
       "      <td>1.454594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557625</td>\n",
       "      <td>1.733625</td>\n",
       "      <td>0.204131</td>\n",
       "      <td>0.319043</td>\n",
       "      <td>1.435537</td>\n",
       "      <td>-3.006604</td>\n",
       "      <td>-2.469166</td>\n",
       "      <td>0.142097</td>\n",
       "      <td>-0.286942</td>\n",
       "      <td>-0.000472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>1.101763</td>\n",
       "      <td>-0.755330</td>\n",
       "      <td>-1.075515</td>\n",
       "      <td>0.272517</td>\n",
       "      <td>0.150855</td>\n",
       "      <td>-1.116584</td>\n",
       "      <td>-1.450344</td>\n",
       "      <td>1.098596</td>\n",
       "      <td>-2.823574</td>\n",
       "      <td>-0.606317</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.363034</td>\n",
       "      <td>0.068018</td>\n",
       "      <td>0.527653</td>\n",
       "      <td>0.706851</td>\n",
       "      <td>2.122260</td>\n",
       "      <td>-1.562261</td>\n",
       "      <td>1.167268</td>\n",
       "      <td>-0.187608</td>\n",
       "      <td>-0.840015</td>\n",
       "      <td>-0.606366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-2.574324</td>\n",
       "      <td>-2.177396</td>\n",
       "      <td>-0.519794</td>\n",
       "      <td>0.873067</td>\n",
       "      <td>0.255089</td>\n",
       "      <td>0.362654</td>\n",
       "      <td>1.874123</td>\n",
       "      <td>-0.172567</td>\n",
       "      <td>0.138581</td>\n",
       "      <td>0.649002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283732</td>\n",
       "      <td>1.828638</td>\n",
       "      <td>0.355169</td>\n",
       "      <td>2.224137</td>\n",
       "      <td>-0.019704</td>\n",
       "      <td>-1.720095</td>\n",
       "      <td>-0.491752</td>\n",
       "      <td>-0.623703</td>\n",
       "      <td>0.114877</td>\n",
       "      <td>0.037144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-2.112787</td>\n",
       "      <td>-0.805857</td>\n",
       "      <td>-0.152196</td>\n",
       "      <td>-0.386873</td>\n",
       "      <td>1.179263</td>\n",
       "      <td>0.769944</td>\n",
       "      <td>0.988461</td>\n",
       "      <td>0.705040</td>\n",
       "      <td>-1.080020</td>\n",
       "      <td>0.141607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764955</td>\n",
       "      <td>-0.625984</td>\n",
       "      <td>3.905757</td>\n",
       "      <td>0.828790</td>\n",
       "      <td>0.657934</td>\n",
       "      <td>0.955136</td>\n",
       "      <td>1.083874</td>\n",
       "      <td>-0.787815</td>\n",
       "      <td>0.980592</td>\n",
       "      <td>1.571381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "the   0.157692 -1.962667 -0.021549 -1.304941  1.056042 -1.409629  1.633958   \n",
       "what -0.950905 -2.366135 -2.126145  0.122318  0.181524 -0.635590  2.056228   \n",
       "is    1.101763 -0.755330 -1.075515  0.272517  0.150855 -1.116584 -1.450344   \n",
       "a    -2.574324 -2.177396 -0.519794  0.873067  0.255089  0.362654  1.874123   \n",
       "to   -2.112787 -0.805857 -0.152196 -0.386873  1.179263  0.769944  0.988461   \n",
       "\n",
       "           7         8         9    ...       246       247       248  \\\n",
       "the  -0.239701  0.867131  1.081947  ...  0.443057  1.110562  0.749143   \n",
       "what -0.545641  0.922501  1.454594  ...  0.557625  1.733625  0.204131   \n",
       "is    1.098596 -2.823574 -0.606317  ... -2.363034  0.068018  0.527653   \n",
       "a    -0.172567  0.138581  0.649002  ...  0.283732  1.828638  0.355169   \n",
       "to    0.705040 -1.080020  0.141607  ...  0.764955 -0.625984  3.905757   \n",
       "\n",
       "           249       250       251       252       253       254       255  \n",
       "the   0.645440  1.455143 -2.426267 -0.507591  0.627361 -0.553571  1.617401  \n",
       "what  0.319043  1.435537 -3.006604 -2.469166  0.142097 -0.286942 -0.000472  \n",
       "is    0.706851  2.122260 -1.562261  1.167268 -0.187608 -0.840015 -0.606366  \n",
       "a     2.224137 -0.019704 -1.720095 -0.491752 -0.623703  0.114877  0.037144  \n",
       "to    0.828790  0.657934  0.955136  1.083874 -0.787815  0.980592  1.571381  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_unpack = [(word, idx) for word, idx in word_vec.wv.key_to_index.items()]\n",
    "\n",
    "tokens, indexes = zip(*word_vec_unpack)\n",
    "\n",
    "word_vec_df = pd.DataFrame(word_vec.wv.vectors[indexes, :], index=tokens)\n",
    "\n",
    "word_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_array = np.array(preprocessed_df['question_text'])\n",
    "\n",
    "model_array = np.array([word_vec_df.loc[doc].mean(axis=0) for doc in tokenized_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.046192</td>\n",
       "      <td>-0.871497</td>\n",
       "      <td>-0.419549</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>0.202806</td>\n",
       "      <td>-0.606084</td>\n",
       "      <td>0.209398</td>\n",
       "      <td>0.071741</td>\n",
       "      <td>-0.685661</td>\n",
       "      <td>0.107178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569011</td>\n",
       "      <td>-0.120733</td>\n",
       "      <td>0.453698</td>\n",
       "      <td>0.941927</td>\n",
       "      <td>-1.131483</td>\n",
       "      <td>0.181631</td>\n",
       "      <td>0.115580</td>\n",
       "      <td>-0.154066</td>\n",
       "      <td>0.445269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.540810</td>\n",
       "      <td>-0.317784</td>\n",
       "      <td>-0.074230</td>\n",
       "      <td>0.189299</td>\n",
       "      <td>0.149130</td>\n",
       "      <td>-0.549548</td>\n",
       "      <td>0.549128</td>\n",
       "      <td>-0.092174</td>\n",
       "      <td>-0.336563</td>\n",
       "      <td>0.383196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214367</td>\n",
       "      <td>-0.543109</td>\n",
       "      <td>0.588254</td>\n",
       "      <td>0.154767</td>\n",
       "      <td>-0.519360</td>\n",
       "      <td>-0.711660</td>\n",
       "      <td>0.557392</td>\n",
       "      <td>0.435211</td>\n",
       "      <td>-0.386071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020519</td>\n",
       "      <td>-0.015671</td>\n",
       "      <td>-0.977683</td>\n",
       "      <td>-0.270581</td>\n",
       "      <td>0.911020</td>\n",
       "      <td>-0.025638</td>\n",
       "      <td>-0.023462</td>\n",
       "      <td>-0.125082</td>\n",
       "      <td>0.529428</td>\n",
       "      <td>0.042831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695944</td>\n",
       "      <td>-0.397305</td>\n",
       "      <td>-0.829240</td>\n",
       "      <td>0.231845</td>\n",
       "      <td>0.141830</td>\n",
       "      <td>-0.037864</td>\n",
       "      <td>0.282534</td>\n",
       "      <td>-0.184620</td>\n",
       "      <td>-0.592754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.026200</td>\n",
       "      <td>-0.217017</td>\n",
       "      <td>-0.387425</td>\n",
       "      <td>-0.095369</td>\n",
       "      <td>-0.404747</td>\n",
       "      <td>0.234138</td>\n",
       "      <td>0.114563</td>\n",
       "      <td>-0.325986</td>\n",
       "      <td>-0.273905</td>\n",
       "      <td>-0.341776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536481</td>\n",
       "      <td>-0.146647</td>\n",
       "      <td>0.674276</td>\n",
       "      <td>0.196746</td>\n",
       "      <td>-1.400912</td>\n",
       "      <td>-0.478400</td>\n",
       "      <td>-0.205022</td>\n",
       "      <td>-0.207162</td>\n",
       "      <td>0.522226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.688531</td>\n",
       "      <td>-0.207328</td>\n",
       "      <td>-1.431810</td>\n",
       "      <td>0.250045</td>\n",
       "      <td>-0.192462</td>\n",
       "      <td>0.053853</td>\n",
       "      <td>0.323942</td>\n",
       "      <td>-0.575614</td>\n",
       "      <td>0.449814</td>\n",
       "      <td>0.424915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452518</td>\n",
       "      <td>0.409565</td>\n",
       "      <td>-0.202967</td>\n",
       "      <td>0.703024</td>\n",
       "      <td>0.252340</td>\n",
       "      <td>-0.531481</td>\n",
       "      <td>0.274658</td>\n",
       "      <td>-0.384855</td>\n",
       "      <td>0.521392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.046192 -0.871497 -0.419549  0.051906  0.202806 -0.606084  0.209398   \n",
       "1 -0.540810 -0.317784 -0.074230  0.189299  0.149130 -0.549548  0.549128   \n",
       "2  0.020519 -0.015671 -0.977683 -0.270581  0.911020 -0.025638 -0.023462   \n",
       "3 -0.026200 -0.217017 -0.387425 -0.095369 -0.404747  0.234138  0.114563   \n",
       "4 -0.688531 -0.207328 -1.431810  0.250045 -0.192462  0.053853  0.323942   \n",
       "\n",
       "          7         8         9  ...       247       248       249       250  \\\n",
       "0  0.071741 -0.685661  0.107178  ...  0.569011 -0.120733  0.453698  0.941927   \n",
       "1 -0.092174 -0.336563  0.383196  ...  0.214367 -0.543109  0.588254  0.154767   \n",
       "2 -0.125082  0.529428  0.042831  ...  0.695944 -0.397305 -0.829240  0.231845   \n",
       "3 -0.325986 -0.273905 -0.341776  ...  0.536481 -0.146647  0.674276  0.196746   \n",
       "4 -0.575614  0.449814  0.424915  ...  0.452518  0.409565 -0.202967  0.703024   \n",
       "\n",
       "        251       252       253       254       255  target  \n",
       "0 -1.131483  0.181631  0.115580 -0.154066  0.445269       0  \n",
       "1 -0.519360 -0.711660  0.557392  0.435211 -0.386071       0  \n",
       "2  0.141830 -0.037864  0.282534 -0.184620 -0.592754       0  \n",
       "3 -1.400912 -0.478400 -0.205022 -0.207162  0.522226       0  \n",
       "4  0.252340 -0.531481  0.274658 -0.384855  0.521392       0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = pd.DataFrame(model_array)\n",
    "model_df[\"target\"] = preprocessed_df[\"target\"]\n",
    "\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model_df[\"target\"]\n",
    "X = model_df.drop([\"target\"], axis=1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631016</th>\n",
       "      <td>-0.770446</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>0.021556</td>\n",
       "      <td>-0.448783</td>\n",
       "      <td>-0.643888</td>\n",
       "      <td>-0.400822</td>\n",
       "      <td>0.187452</td>\n",
       "      <td>-0.155320</td>\n",
       "      <td>-0.161874</td>\n",
       "      <td>-0.046565</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.043934</td>\n",
       "      <td>-0.551572</td>\n",
       "      <td>0.966854</td>\n",
       "      <td>-0.549450</td>\n",
       "      <td>0.039330</td>\n",
       "      <td>-0.641822</td>\n",
       "      <td>-0.431646</td>\n",
       "      <td>-0.466421</td>\n",
       "      <td>0.088508</td>\n",
       "      <td>0.680383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34150</th>\n",
       "      <td>0.109974</td>\n",
       "      <td>-1.061241</td>\n",
       "      <td>-0.366217</td>\n",
       "      <td>0.335971</td>\n",
       "      <td>0.501445</td>\n",
       "      <td>0.184031</td>\n",
       "      <td>-0.191152</td>\n",
       "      <td>0.425920</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>-0.007113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294545</td>\n",
       "      <td>1.052991</td>\n",
       "      <td>0.172658</td>\n",
       "      <td>0.261178</td>\n",
       "      <td>0.637437</td>\n",
       "      <td>-1.659547</td>\n",
       "      <td>-0.579092</td>\n",
       "      <td>0.054213</td>\n",
       "      <td>-0.285278</td>\n",
       "      <td>0.097135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213502</th>\n",
       "      <td>0.032301</td>\n",
       "      <td>-0.620044</td>\n",
       "      <td>-0.483492</td>\n",
       "      <td>0.136974</td>\n",
       "      <td>-0.117304</td>\n",
       "      <td>-0.220404</td>\n",
       "      <td>0.369797</td>\n",
       "      <td>-0.102097</td>\n",
       "      <td>-0.545628</td>\n",
       "      <td>0.184739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.432680</td>\n",
       "      <td>0.469448</td>\n",
       "      <td>0.624652</td>\n",
       "      <td>-0.255495</td>\n",
       "      <td>-0.272271</td>\n",
       "      <td>-1.260071</td>\n",
       "      <td>-0.109352</td>\n",
       "      <td>-0.140307</td>\n",
       "      <td>-0.486599</td>\n",
       "      <td>0.628950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96871</th>\n",
       "      <td>0.009917</td>\n",
       "      <td>-0.453236</td>\n",
       "      <td>-0.382034</td>\n",
       "      <td>0.411499</td>\n",
       "      <td>0.095838</td>\n",
       "      <td>0.207947</td>\n",
       "      <td>0.613289</td>\n",
       "      <td>-0.203824</td>\n",
       "      <td>0.438343</td>\n",
       "      <td>0.785015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085962</td>\n",
       "      <td>0.274461</td>\n",
       "      <td>0.590008</td>\n",
       "      <td>-0.164559</td>\n",
       "      <td>-0.649510</td>\n",
       "      <td>-0.053432</td>\n",
       "      <td>0.290500</td>\n",
       "      <td>-0.539831</td>\n",
       "      <td>-0.450243</td>\n",
       "      <td>0.464656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225411</th>\n",
       "      <td>0.169577</td>\n",
       "      <td>-0.299672</td>\n",
       "      <td>-0.398752</td>\n",
       "      <td>-0.113930</td>\n",
       "      <td>0.273852</td>\n",
       "      <td>0.407381</td>\n",
       "      <td>0.451407</td>\n",
       "      <td>-0.440717</td>\n",
       "      <td>0.185153</td>\n",
       "      <td>0.370212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178180</td>\n",
       "      <td>0.096549</td>\n",
       "      <td>0.754463</td>\n",
       "      <td>0.181592</td>\n",
       "      <td>0.159482</td>\n",
       "      <td>-0.016935</td>\n",
       "      <td>-1.160714</td>\n",
       "      <td>-0.146408</td>\n",
       "      <td>0.324497</td>\n",
       "      <td>0.039184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292379</th>\n",
       "      <td>-0.027913</td>\n",
       "      <td>-0.311410</td>\n",
       "      <td>-0.480998</td>\n",
       "      <td>0.234448</td>\n",
       "      <td>0.746714</td>\n",
       "      <td>-0.095122</td>\n",
       "      <td>1.005669</td>\n",
       "      <td>0.281209</td>\n",
       "      <td>0.738140</td>\n",
       "      <td>0.460017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751699</td>\n",
       "      <td>-0.056500</td>\n",
       "      <td>0.830714</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>-0.141313</td>\n",
       "      <td>0.041298</td>\n",
       "      <td>-0.305492</td>\n",
       "      <td>-0.291452</td>\n",
       "      <td>0.370704</td>\n",
       "      <td>0.289716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422345</th>\n",
       "      <td>-0.341777</td>\n",
       "      <td>-0.504992</td>\n",
       "      <td>-0.792512</td>\n",
       "      <td>1.702541</td>\n",
       "      <td>-0.135418</td>\n",
       "      <td>0.688778</td>\n",
       "      <td>0.622097</td>\n",
       "      <td>-0.061926</td>\n",
       "      <td>0.344063</td>\n",
       "      <td>0.783900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322626</td>\n",
       "      <td>0.465585</td>\n",
       "      <td>0.752223</td>\n",
       "      <td>-0.258982</td>\n",
       "      <td>0.443352</td>\n",
       "      <td>0.277452</td>\n",
       "      <td>-0.683634</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>-0.234258</td>\n",
       "      <td>0.098046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582487</th>\n",
       "      <td>-0.983406</td>\n",
       "      <td>-0.589381</td>\n",
       "      <td>-1.216957</td>\n",
       "      <td>0.423686</td>\n",
       "      <td>0.911840</td>\n",
       "      <td>-0.518576</td>\n",
       "      <td>1.078491</td>\n",
       "      <td>0.144351</td>\n",
       "      <td>1.373897</td>\n",
       "      <td>0.533781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623604</td>\n",
       "      <td>-0.246031</td>\n",
       "      <td>1.252538</td>\n",
       "      <td>0.242172</td>\n",
       "      <td>-1.768718</td>\n",
       "      <td>1.016639</td>\n",
       "      <td>-0.595163</td>\n",
       "      <td>-1.390513</td>\n",
       "      <td>0.596418</td>\n",
       "      <td>0.005012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501996</th>\n",
       "      <td>0.145803</td>\n",
       "      <td>-0.167092</td>\n",
       "      <td>0.104261</td>\n",
       "      <td>0.009808</td>\n",
       "      <td>-0.245619</td>\n",
       "      <td>-0.445027</td>\n",
       "      <td>-0.419308</td>\n",
       "      <td>0.297254</td>\n",
       "      <td>0.211868</td>\n",
       "      <td>0.208344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.855199</td>\n",
       "      <td>-0.060997</td>\n",
       "      <td>-0.103108</td>\n",
       "      <td>0.209435</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>-1.325326</td>\n",
       "      <td>-0.226904</td>\n",
       "      <td>-0.142551</td>\n",
       "      <td>0.276801</td>\n",
       "      <td>-0.181245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234633</th>\n",
       "      <td>-0.430701</td>\n",
       "      <td>-0.304227</td>\n",
       "      <td>-0.588040</td>\n",
       "      <td>0.334860</td>\n",
       "      <td>0.211060</td>\n",
       "      <td>0.177190</td>\n",
       "      <td>0.362833</td>\n",
       "      <td>-0.151126</td>\n",
       "      <td>0.439476</td>\n",
       "      <td>0.361157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444736</td>\n",
       "      <td>0.036262</td>\n",
       "      <td>-0.235971</td>\n",
       "      <td>0.244875</td>\n",
       "      <td>-0.033340</td>\n",
       "      <td>-0.374107</td>\n",
       "      <td>-0.169202</td>\n",
       "      <td>0.047533</td>\n",
       "      <td>0.437417</td>\n",
       "      <td>0.226912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130613 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "631016 -0.770446 -0.005377  0.021556 -0.448783 -0.643888 -0.400822  0.187452   \n",
       "34150   0.109974 -1.061241 -0.366217  0.335971  0.501445  0.184031 -0.191152   \n",
       "213502  0.032301 -0.620044 -0.483492  0.136974 -0.117304 -0.220404  0.369797   \n",
       "96871   0.009917 -0.453236 -0.382034  0.411499  0.095838  0.207947  0.613289   \n",
       "225411  0.169577 -0.299672 -0.398752 -0.113930  0.273852  0.407381  0.451407   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "292379 -0.027913 -0.311410 -0.480998  0.234448  0.746714 -0.095122  1.005669   \n",
       "422345 -0.341777 -0.504992 -0.792512  1.702541 -0.135418  0.688778  0.622097   \n",
       "582487 -0.983406 -0.589381 -1.216957  0.423686  0.911840 -0.518576  1.078491   \n",
       "501996  0.145803 -0.167092  0.104261  0.009808 -0.245619 -0.445027 -0.419308   \n",
       "234633 -0.430701 -0.304227 -0.588040  0.334860  0.211060  0.177190  0.362833   \n",
       "\n",
       "             7         8         9    ...       246       247       248  \\\n",
       "631016 -0.155320 -0.161874 -0.046565  ... -1.043934 -0.551572  0.966854   \n",
       "34150   0.425920  0.007570 -0.007113  ... -0.294545  1.052991  0.172658   \n",
       "213502 -0.102097 -0.545628  0.184739  ... -0.432680  0.469448  0.624652   \n",
       "96871  -0.203824  0.438343  0.785015  ...  0.085962  0.274461  0.590008   \n",
       "225411 -0.440717  0.185153  0.370212  ...  0.178180  0.096549  0.754463   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "292379  0.281209  0.738140  0.460017  ...  0.751699 -0.056500  0.830714   \n",
       "422345 -0.061926  0.344063  0.783900  ...  0.322626  0.465585  0.752223   \n",
       "582487  0.144351  1.373897  0.533781  ...  0.623604 -0.246031  1.252538   \n",
       "501996  0.297254  0.211868  0.208344  ... -0.855199 -0.060997 -0.103108   \n",
       "234633 -0.151126  0.439476  0.361157  ...  0.444736  0.036262 -0.235971   \n",
       "\n",
       "             249       250       251       252       253       254       255  \n",
       "631016 -0.549450  0.039330 -0.641822 -0.431646 -0.466421  0.088508  0.680383  \n",
       "34150   0.261178  0.637437 -1.659547 -0.579092  0.054213 -0.285278  0.097135  \n",
       "213502 -0.255495 -0.272271 -1.260071 -0.109352 -0.140307 -0.486599  0.628950  \n",
       "96871  -0.164559 -0.649510 -0.053432  0.290500 -0.539831 -0.450243  0.464656  \n",
       "225411  0.181592  0.159482 -0.016935 -1.160714 -0.146408  0.324497  0.039184  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "292379  0.009903 -0.141313  0.041298 -0.305492 -0.291452  0.370704  0.289716  \n",
       "422345 -0.258982  0.443352  0.277452 -0.683634  0.008056 -0.234258  0.098046  \n",
       "582487  0.242172 -1.768718  1.016639 -0.595163 -1.390513  0.596418  0.005012  \n",
       "501996  0.209435  0.044648 -1.325326 -0.226904 -0.142551  0.276801 -0.181245  \n",
       "234633  0.244875 -0.033340 -0.374107 -0.169202  0.047533  0.437417  0.226912  \n",
       "\n",
       "[130613 rows x 256 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight={1: 4})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression(solver='lbfgs', class_weight={1:4})\n",
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5964/2277119527.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \"\"\"\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    112\u001b[0m         ):\n\u001b[0;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"infinity\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"NaN, infinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "y_hat = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "       ... \n",
       "251    True\n",
       "252    True\n",
       "253    True\n",
       "254    True\n",
       "255    True\n",
       "Length: 256, dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[np.isnan(X_test)] = np.median(X_test[~np.isnan(X_test)])\n",
    "np.isnan(X_test).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5964/634942357.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    796\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m         \"\"\"\n\u001b[1;32m--> 798\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    567\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[0;32m    568\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    112\u001b[0m         ):\n\u001b[0;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"infinity\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"NaN, infinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "r = RandomForestClassifier()\n",
    "r.fit(X_train,y_train)\n",
    "pred=r.predict(X_test)\n",
    "pred = pred.astype(int)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
